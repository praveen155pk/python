{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficient Matrix is : \n",
      "\n",
      " [[1.00e+00 1.30e+03 2.70e+00]\n",
      " [1.00e+00 1.26e+03 3.70e+00]\n",
      " [1.00e+00 1.22e+03 2.90e+00]\n",
      " [1.00e+00 1.18e+03 2.50e+00]\n",
      " [1.00e+00 1.06e+03 3.90e+00]\n",
      " [1.00e+00 1.14e+03 2.10e+00]\n",
      " [1.00e+00 1.10e+03 3.50e+00]\n",
      " [1.00e+00 1.02e+03 3.30e+00]\n",
      " [1.00e+00 9.80e+02 2.30e+00]\n",
      " [1.00e+00 9.40e+02 3.10e+00]]\n",
      "\n",
      "Dependent Matrix is : \n",
      "\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Regression Coefficients are : \n",
      "\n",
      " [[-3.83919635e+00]\n",
      " [ 3.23263173e-03]\n",
      " [ 2.39549603e-01]]\n",
      "\n",
      "Yhat Matrix is : \n",
      "\n",
      " [[ 1.01000883]\n",
      " [ 1.12025316]\n",
      " [ 0.79930821]\n",
      " [ 0.5741831 ]\n",
      " [ 0.52163674]\n",
      " [ 0.34905799]\n",
      " [ 0.55512217]\n",
      " [ 0.24860171]\n",
      " [-0.12025316]\n",
      " [-0.05791875]]\n",
      "\n",
      "Error Matrix is : \n",
      "\n",
      " [[-0.01000883]\n",
      " [-0.12025316]\n",
      " [ 0.20069179]\n",
      " [ 0.4258169 ]\n",
      " [ 0.47836326]\n",
      " [-0.34905799]\n",
      " [-0.55512217]\n",
      " [-0.24860171]\n",
      " [ 0.12025316]\n",
      " [ 0.05791875]]\n",
      "\n",
      "Sum of squares due to error is : \n",
      "\n",
      " [[0.97460995]]\n",
      "\n",
      "Sum of squares due to total is : \n",
      "\n",
      " [[2.5]]\n",
      "\n",
      "Sum of squares due to regression model is : \n",
      "\n",
      " [[1.52539005]]\n"
     ]
    }
   ],
   "source": [
    "# LDA 1\n",
    "import numpy as np\n",
    "x=np.array([[1,1300,2.7],[1,1260,3.7],[1,1220,2.9],[1,1180,2.5],[1,1060,3.9],[1,1140,2.1],[1,1100,3.5],[1,1020,3.3],[1,980,2.3],[1,940,3.1]])\n",
    "print('\\nCoefficient Matrix is : \\n\\n',x)\n",
    "yt=np.array([[1,1,1,1,1,0,0,0,0,0]])\n",
    "y=np.transpose(yt)\n",
    "print('\\nDependent Matrix is : \\n\\n',y)\n",
    "xt=np.transpose(x)\n",
    "betahat=np.matmul(np.linalg.inv(np.matmul(xt,x)),np.matmul(xt,y))\n",
    "print('\\nRegression Coefficients are : \\n\\n',betahat)\n",
    "yhat=np.matmul(x,betahat)\n",
    "print('\\nYhat Matrix is : \\n\\n',yhat)\n",
    "eps=y-yhat\n",
    "print('\\nError Matrix is : \\n\\n',eps)\n",
    "sse=np.matmul(np.transpose(eps),eps)\n",
    "print('\\nSum of squares due to error is : \\n\\n',sse)\n",
    "sst=np.matmul(np.transpose(y-np.mean(y,axis=0)),y-np.mean(y,axis=0))\n",
    "print('\\nSum of squares due to total is : \\n\\n',sst)\n",
    "ssr=sst-sse\n",
    "print('\\nSum of squares due to regression model is : \\n\\n',ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Matrix is:\n",
      "\n",
      "[[2.95 6.63]\n",
      " [2.53 7.79]\n",
      " [3.57 5.65]\n",
      " [3.16 5.47]]\n",
      "\n",
      "Mean of A:\n",
      "\n",
      "[3.0525 6.385 ]\n",
      "\n",
      "B Matrix is:\n",
      "\n",
      "[[2.58 4.46]\n",
      " [2.16 6.22]\n",
      " [3.27 3.52]]\n",
      "\n",
      "Mean of B:\n",
      "\n",
      "[2.67       4.73333333]\n",
      "\n",
      "The Full Matrix is :\n",
      "\n",
      "[[2.95 6.63]\n",
      " [2.53 7.79]\n",
      " [3.57 5.65]\n",
      " [3.16 5.47]\n",
      " [2.58 4.46]\n",
      " [2.16 6.22]\n",
      " [3.27 3.52]]\n",
      "\n",
      "Mean of Full Matrix:\n",
      "\n",
      "[2.88857143 5.67714286]\n",
      "\n",
      "The Scaled Matrix is :\n",
      "\n",
      "[[ 0.06142857  0.95285714]\n",
      " [-0.35857143  2.11285714]\n",
      " [ 0.68142857 -0.02714286]\n",
      " [ 0.27142857 -0.20714286]\n",
      " [-0.30857143 -1.21714286]\n",
      " [-0.72857143  0.54285714]\n",
      " [ 0.38142857 -2.15714286]]\n",
      "\n",
      "The Variance Covariance Matrix is :\n",
      "\n",
      "[[ 0.21 -0.23]\n",
      " [-0.23  1.69]]\n",
      "\n",
      "The inverse of Pooled Covariance Matrix is :\n",
      "\n",
      "[[5.73171449 0.78221769]\n",
      " [0.78221769 0.69771022]]\n",
      "\n",
      "f1 = 43.83\n",
      "f2 = 43.86\n"
     ]
    }
   ],
   "source": [
    "# LDA 2\n",
    "import numpy as np \n",
    "import math\n",
    "obs=np.array([2.81,5.46])\n",
    "A=np.array([[2.95,6.63],[2.53,7.79],[3.57,5.65],[3.16,5.47]])\n",
    "print('\\nA Matrix is:\\n\\n{}'.format(A))\n",
    "A=np.mean(A,axis=0)\n",
    "print('\\nMean of A:\\n\\n{}'.format(A))\n",
    "B=np.array([[2.58,4.46],[2.16,6.22],[3.27,3.52]])\n",
    "print('\\nB Matrix is:\\n\\n{}'.format(B))\n",
    "B=B.mean(axis=0)\n",
    "print('\\nMean of B:\\n\\n{}'.format(B))\n",
    "FM=np.array([[2.95,6.63],[2.53,7.79],[3.57,5.65],[3.16,5.47],[2.58,4.46],[2.16,6.22],[3.27,3.52]])\n",
    "print('\\nThe Full Matrix is :\\n\\n{}'.format(FM))\n",
    "print('\\nMean of Full Matrix:\\n\\n{}'.format(np.mean(FM,axis=0)))\n",
    "FM = (FM-np.mean(FM, axis=0))\n",
    "print('\\nThe Scaled Matrix is :\\n\\n{}'.format(FM))\n",
    "PoolCov=np.matmul(np.transpose(FM),FM)/7\n",
    "print('\\nThe Variance Covariance Matrix is :\\n\\n{}'.format(np.round(PoolCov,2)))\n",
    "pcinv=np.linalg.inv(PoolCov)\n",
    "print('\\nThe inverse of Pooled Covariance Matrix is :\\n\\n{}'.format(pcinv))\n",
    "mu1=A\n",
    "mu2=B\n",
    "f1=np.matmul(np.matmul(mu1,pcinv),np.transpose(obs))-(0.5*(np.matmul(np.matmul(mu1,pcinv),np.transpose(mu1))))+(math.log(4/7))\n",
    "f2=np.matmul(np.matmul(mu2,pcinv),np.transpose(obs))-(0.5*(np.matmul(np.matmul(mu2,pcinv),np.transpose(mu2))))+(math.log(3/7))\n",
    "print('\\nf1 = {}'.format(np.round(f1,2)))\n",
    "print('f2 = {}'.format(np.round(f2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Matrix is:\n",
      "\n",
      "[[4 2]\n",
      " [2 4]\n",
      " [2 3]\n",
      " [3 6]\n",
      " [4 4]]\n",
      "\n",
      "Mean of A:\n",
      "\n",
      "[3.  3.8]\n",
      "\n",
      "B Matrix is:\n",
      "\n",
      "[[ 9 10]\n",
      " [ 6  8]\n",
      " [ 9  5]\n",
      " [ 8  7]\n",
      " [10  8]]\n",
      "\n",
      "Mean of B:\n",
      "\n",
      "[8.4 7.6]\n",
      "\n",
      "The Full Matrix is :\n",
      "\n",
      "[[ 4  2]\n",
      " [ 2  4]\n",
      " [ 2  3]\n",
      " [ 3  6]\n",
      " [ 4  4]\n",
      " [ 9 10]\n",
      " [ 6  8]\n",
      " [ 9  5]\n",
      " [ 8  7]\n",
      " [10  8]]\n",
      "\n",
      "Mean of Full Matrix:\n",
      "\n",
      "[5.7 5.7]\n",
      "\n",
      "The Scaled Matrix is :\n",
      "\n",
      "[[-1.7 -3.7]\n",
      " [-3.7 -1.7]\n",
      " [-3.7 -2.7]\n",
      " [-2.7  0.3]\n",
      " [-1.7 -1.7]\n",
      " [ 3.3  4.3]\n",
      " [ 0.3  2.3]\n",
      " [ 3.3 -0.7]\n",
      " [ 2.3  1.3]\n",
      " [ 4.3  2.3]]\n",
      "\n",
      "The Variance Covariance Matrix is :\n",
      "\n",
      "[[8.61 5.01]\n",
      " [5.01 5.81]]\n",
      "\n",
      "The inverse of Pooled Covariance Matrix is :\n",
      "\n",
      "[[ 0.23310865 -0.20101107]\n",
      " [-0.20101107  0.34545017]]\n",
      "\n",
      "\n",
      "f1 = 1.99\n",
      "f2 = 1.71\n"
     ]
    }
   ],
   "source": [
    "# LDA 3\n",
    "import numpy as np \n",
    "import math\n",
    "obs=np.array([5,6])\n",
    "A=np.array([[4,2],[2,4],[2,3],[3,6],[4,4]])\n",
    "print('\\nA Matrix is:\\n\\n{}'.format(A))\n",
    "A=A.mean(axis=0)\n",
    "print('\\nMean of A:\\n\\n{}'.format(A))\n",
    "B=np.array([[9,10],[6,8],[9,5],[8,7],[10,8]])\n",
    "print('\\nB Matrix is:\\n\\n{}'.format(B))\n",
    "B=B.mean(axis=0)\n",
    "print('\\nMean of B:\\n\\n{}'.format(B))\n",
    "FM=np.array([[4,2],[2,4],[2,3],[3,6],[4,4],[9,10],[6,8],[9,5],[8,7],[10,8]])\n",
    "print('\\nThe Full Matrix is :\\n\\n{}'.format(FM))\n",
    "print('\\nMean of Full Matrix:\\n\\n{}'.format(np.mean(FM,axis=0)))\n",
    "FM = (FM - np.mean(FM, axis=0))\n",
    "print('\\nThe Scaled Matrix is :\\n\\n{}'.format(FM))\n",
    "PoolCov=np.dot(np.transpose(FM),FM)/10\n",
    "print('\\nThe Variance Covariance Matrix is :\\n\\n{}'.format(np.round(PoolCov,2)))\n",
    "pcinv=np.linalg.inv(PoolCov)\n",
    "print('\\nThe inverse of Pooled Covariance Matrix is :\\n\\n{}'.format(pcinv))\n",
    "mu1=A\n",
    "mu2=B\n",
    "f1=np.dot(np.dot(mu1,pcinv),np.transpose(obs))-(0.5*(np.dot(np.dot(mu1,pcinv),np.transpose(mu1))))+(math.log(5/10))\n",
    "f2=np.dot(np.dot(mu2,pcinv),np.transpose(obs))-(0.5*(np.dot(np.dot(mu2,pcinv),np.transpose(mu2))))+(math.log(5/10))\n",
    "print('\\n\\nf1 = {}'.format(np.round(f1,2)))\n",
    "print('f2 = {}'.format(np.round(f2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Matrix is:\n",
      "\n",
      "[[1 2]\n",
      " [2 3]\n",
      " [3 3]\n",
      " [4 5]\n",
      " [5 5]]\n",
      "\n",
      "Mean of A:\n",
      "\n",
      "[3.  3.6]\n",
      "\n",
      "B Matrix is:\n",
      "\n",
      "[[4 2]\n",
      " [5 0]\n",
      " [5 2]\n",
      " [3 2]\n",
      " [5 3]\n",
      " [6 3]]\n",
      "\n",
      "Mean of B:\n",
      "\n",
      "[4.66666667 2.        ]\n",
      "\n",
      "The Full Matrix is :\n",
      "\n",
      "[[1 2]\n",
      " [2 3]\n",
      " [3 3]\n",
      " [4 5]\n",
      " [5 5]\n",
      " [4 2]\n",
      " [5 0]\n",
      " [5 2]\n",
      " [3 2]\n",
      " [5 3]\n",
      " [6 3]]\n",
      "\n",
      "Mean of Full Matrix:\n",
      "\n",
      "[3.90909091 2.72727273]\n",
      "\n",
      "The Scaled Matrix is :\n",
      "\n",
      "[[-2.90909091 -0.72727273]\n",
      " [-1.90909091  0.27272727]\n",
      " [-0.90909091  0.27272727]\n",
      " [ 0.09090909  2.27272727]\n",
      " [ 1.09090909  2.27272727]\n",
      " [ 0.09090909 -0.72727273]\n",
      " [ 1.09090909 -2.72727273]\n",
      " [ 1.09090909 -0.72727273]\n",
      " [-0.90909091 -0.72727273]\n",
      " [ 1.09090909  0.27272727]\n",
      " [ 2.09090909  0.27272727]]\n",
      "\n",
      "The Variance Covariance Matrix is :\n",
      "\n",
      "[[2.08 0.16]\n",
      " [0.16 1.83]]\n",
      "\n",
      "The inverse of Pooled Covariance Matrix is :\n",
      "\n",
      "[[ 0.48327726 -0.04136157]\n",
      " [-0.04136157  0.548585  ]]\n",
      "\n",
      "\n",
      "f1 = 6.49\n",
      "f2 = 7.39\n"
     ]
    }
   ],
   "source": [
    "# LDA 4\n",
    "import numpy as np \n",
    "import math\n",
    "obs=np.array([5.1,3.2])#observations to be classified\n",
    "A=np.array([[1,2],[2,3],[3,3],[4,5],[5,5]])\n",
    "print('\\nA Matrix is:\\n\\n{}'.format(A))\n",
    "A=A.mean(axis=0)\n",
    "print('\\nMean of A:\\n\\n{}'.format(A))\n",
    "B=np.array([[4,2],[5,0],[5,2],[3,2],[5,3],[6,3]])\n",
    "print('\\nB Matrix is:\\n\\n{}'.format(B))\n",
    "B=B.mean(axis=0)\n",
    "print('\\nMean of B:\\n\\n{}'.format(B))\n",
    "FM=np.array([[1,2],[2,3],[3,3],[4,5],[5,5],[4,2],[5,0],[5,2],[3,2],[5,3],[6,3]])\n",
    "print('\\nThe Full Matrix is :\\n\\n{}'.format(FM))\n",
    "print('\\nMean of Full Matrix:\\n\\n{}'.format(np.mean(FM,axis=0)))\n",
    "FM = (FM - np.mean(FM, axis=0))\n",
    "print('\\nThe Scaled Matrix is :\\n\\n{}'.format(FM))\n",
    "PoolCov=np.dot(np.transpose(FM),FM)/11\n",
    "print('\\nThe Variance Covariance Matrix is :\\n\\n{}'.format(np.round(PoolCov,2)))\n",
    "pcinv=np.linalg.inv(PoolCov)\n",
    "print('\\nThe inverse of Pooled Covariance Matrix is :\\n\\n{}'.format(pcinv))\n",
    "mu1=A\n",
    "mu2=B\n",
    "f1=np.dot(np.dot(mu1,pcinv),np.transpose(obs))-(0.5*(np.dot(np.dot(mu1,pcinv),np.transpose(mu1))))+(math.log(5/11))\n",
    "f2=np.dot(np.dot(mu2,pcinv),np.transpose(obs))-(0.5*(np.dot(np.dot(mu2,pcinv),np.transpose(mu2))))+(math.log(6/11))\n",
    "print('\\n\\nf1 = {}'.format(np.round(f1,2)))\n",
    "print('f2 = {}'.format(np.round(f2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given Matrix is \n",
      "\n",
      "[[ 2.   4. ]\n",
      " [ 1.   3. ]\n",
      " [ 0.   1. ]\n",
      " [-1.   0.5]]\n",
      "\n",
      "Col Means are \n",
      "[0.5   2.125]\n",
      "\n",
      "Scaled Matrix is \n",
      "\n",
      "[[ 1.5    1.875]\n",
      " [ 0.5    0.875]\n",
      " [-0.5   -1.125]\n",
      " [-1.5   -1.625]]\n",
      "\n",
      "Variance Covariance Matrix is \n",
      "\n",
      "[[1.25     1.5625  ]\n",
      " [1.5625   2.046875]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "0.03593674297498417, 3.2609382570250163\n",
      "\n",
      "The Eigen vectors are :\n",
      "\n",
      "[[-0.78964958 -0.6135581 ]\n",
      " [ 0.6135581  -0.78964958]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 1\n",
    "import numpy as np \n",
    "X=np.array([[2,4],[1,3],[0,1],[-1,0.5]])\n",
    "print('\\nGiven Matrix is \\n')\n",
    "print(X)\n",
    "print('\\nCol Means are \\n{}'.format(X.mean(axis=0)))\n",
    "X=(X-np.mean(X,axis=0))\n",
    "print('\\nScaled Matrix is \\n')\n",
    "print(X)\n",
    "VarCov=np.dot(np.transpose(X),X)/len(X)\n",
    "print('\\nVariance Covariance Matrix is \\n')\n",
    "print(VarCov)\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}, {}'.format(e1[0][0],e1[0][1]))\n",
    "print('\\nThe Eigen vectors are :\\n')\n",
    "print(e1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given Matrix is \n",
      "\n",
      "[[90 60 90]\n",
      " [90 90 30]\n",
      " [60 60 60]\n",
      " [60 60 90]\n",
      " [30 30 30]]\n",
      "\n",
      "Col Means are \n",
      "[66. 60. 60.]\n",
      "\n",
      "Scaled Matrix is \n",
      "\n",
      "[[ 24.   0.  30.]\n",
      " [ 24.  30. -30.]\n",
      " [ -6.   0.   0.]\n",
      " [ -6.   0.  30.]\n",
      " [-36. -30. -30.]]\n",
      "\n",
      "Variance Covariance Matrix is \n",
      "\n",
      "[[504. 360. 180.]\n",
      " [360. 360.   0.]\n",
      " [180.   0. 720.]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "44.81966028263878, 910.0699530410367, 629.1103866763253\n",
      "\n",
      "The Eigen vectors are :\n",
      "\n",
      "[[ 0.6487899  -0.65580225 -0.3859988 ]\n",
      " [-0.74104991 -0.4291978  -0.51636642]\n",
      " [-0.17296443 -0.62105769  0.7644414 ]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "X=np.array([[90,60,90],[90,90,30],[60,60,60],[60,60,90],[30,30,30]])\n",
    "print('\\nGiven Matrix is \\n')\n",
    "print(X)\n",
    "print('\\nCol Means are \\n{}'.format(X.mean(axis=0)))\n",
    "X=(X-np.mean(X,axis=0))\n",
    "print('\\nScaled Matrix is \\n')\n",
    "print(X)\n",
    "VarCov=np.dot(np.transpose(X),X)/len(X)\n",
    "print('\\nVariance Covariance Matrix is \\n')\n",
    "print(VarCov)\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}, {}, {}'.format(e1[0][0],e1[0][1],e1[0][2]))\n",
    "print('\\nThe Eigen vectors are :\\n')\n",
    "print(e1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given Matrix is \n",
      "\n",
      "[[7 4 3]\n",
      " [4 1 8]\n",
      " [6 3 5]\n",
      " [8 6 1]\n",
      " [8 5 7]\n",
      " [7 2 9]\n",
      " [5 3 3]\n",
      " [9 5 8]\n",
      " [7 4 5]\n",
      " [8 2 2]]\n",
      "\n",
      "Col Means are \n",
      "[6.9 3.5 5.1]\n",
      "\n",
      "Scaled Matrix is \n",
      "\n",
      "[[ 0.1  0.5 -2.1]\n",
      " [-2.9 -2.5  2.9]\n",
      " [-0.9 -0.5 -0.1]\n",
      " [ 1.1  2.5 -4.1]\n",
      " [ 1.1  1.5  1.9]\n",
      " [ 0.1 -1.5  3.9]\n",
      " [-1.9 -0.5 -2.1]\n",
      " [ 2.1  1.5  2.9]\n",
      " [ 0.1  0.5 -0.1]\n",
      " [ 1.1 -1.5 -3.1]]\n",
      "\n",
      "Variance Covariance Matrix is \n",
      "\n",
      "[[ 2.09  1.45 -0.39]\n",
      " [ 1.45  2.25 -1.15]\n",
      " [-0.39 -1.15  7.09]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "[0.67493534 3.30851634 7.44654832]\n",
      "\n",
      "The Eigen vectors are :\n",
      "\n",
      "[[-0.70172743  0.69903712 -0.1375708 ]\n",
      " [ 0.70745703  0.66088917 -0.25045969]\n",
      " [ 0.08416157  0.27307986  0.95830278]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 3\n",
    "import numpy as np \n",
    "X=np.array([[7,4,3],[4,1,8],[6,3,5],[8,6,1],[8,5,7],[7,2,9],[5,3,3],[9,5,8],[7,4,5],[8,2,2]])\n",
    "print('\\nGiven Matrix is \\n')\n",
    "print(X)\n",
    "print('\\nCol Means are \\n{}'.format(X.mean(axis=0)))\n",
    "X=(X-np.mean(X,axis=0))\n",
    "print('\\nScaled Matrix is \\n')\n",
    "print(X)\n",
    "VarCov=np.dot(np.transpose(X),X)/len(X)\n",
    "print('\\nVariance Covariance Matrix is \\n')\n",
    "print(VarCov)\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}'.format(e1[0]))\n",
    "print('\\nThe Eigen vectors are :\\n')\n",
    "print(e1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given Matrix is \n",
      "\n",
      "[[16 16 13 18 16 15 14 16 16]\n",
      " [18 19 15 16 18 18 18 17 19]\n",
      " [17 17 14 14 17 17 20 14 15]\n",
      " [17 17 17 16 18 18 16 20 14]\n",
      " [16 15 17 17 18 18 19 16 19]\n",
      " [15 17 16 17 18 18 15 19 16]\n",
      " [17 16 16 18 18 18 17 15 18]\n",
      " [20 18 16 20 15 15 19 14 17]\n",
      " [14 16 18 17 19 19 18 17 18]\n",
      " [16 16 15 19 18 18 18 15 14]\n",
      " [18 19 16 14 14 14 17 16 13]\n",
      " [19 15 15 18 16 16 18 19 17]]\n",
      "\n",
      "Col Means are \n",
      "\n",
      "[16.9167 16.75   15.6667 17.     17.0833 17.     17.4167 16.5    16.3333]\n",
      "\n",
      "Scaled Matrix is \n",
      "\n",
      "[[-0.9167 -0.75   -2.6667  1.     -1.0833 -2.     -3.4167 -0.5    -0.3333]\n",
      " [ 1.0833  2.25   -0.6667 -1.      0.9167  1.      0.5833  0.5     2.6667]\n",
      " [ 0.0833  0.25   -1.6667 -3.     -0.0833  0.      2.5833 -2.5    -1.3333]\n",
      " [ 0.0833  0.25    1.3333 -1.      0.9167  1.     -1.4167  3.5    -2.3333]\n",
      " [-0.9167 -1.75    1.3333  0.      0.9167  1.      1.5833 -0.5     2.6667]\n",
      " [-1.9167  0.25    0.3333  0.      0.9167  1.     -2.4167  2.5    -0.3333]\n",
      " [ 0.0833 -0.75    0.3333  1.      0.9167  1.     -0.4167 -1.5     1.6667]\n",
      " [ 3.0833  1.25    0.3333  3.     -2.0833 -2.      1.5833 -2.5     0.6667]\n",
      " [-2.9167 -0.75    2.3333  0.      1.9167  2.      0.5833  0.5     1.6667]\n",
      " [-0.9167 -0.75   -0.6667  2.      0.9167  1.      0.5833 -1.5    -2.3333]\n",
      " [ 1.0833  2.25    0.3333 -3.     -3.0833 -3.     -0.4167 -0.5    -3.3333]\n",
      " [ 2.0833 -1.75   -0.6667  1.     -1.0833 -1.      0.5833  2.5     0.6667]]\n",
      "\n",
      "Variance Covariance Matrix is \n",
      "\n",
      "[[ 2.5764  0.8125 -0.5278  0.3333 -1.5764 -1.5     0.8681 -0.5417 -0.1389]\n",
      " [ 0.8125  1.6875 -0.0833 -0.9167 -0.7292 -0.6667  0.0208 -0.2917 -0.6667]\n",
      " [-0.5278 -0.0833  1.7222  0.      0.6944  0.9167  0.3889  0.75    0.5278]\n",
      " [ 0.3333 -0.9167  0.      3.      0.1667  0.0833 -0.25   -0.4167  1.0833]\n",
      " [-1.5764 -0.7292  0.6944  0.1667  2.0764  2.1667  0.0486  0.7083  1.1389]\n",
      " [-1.5    -0.6667  0.9167  0.0833  2.1667  2.3333  0.3333  0.75    1.1667]\n",
      " [ 0.8681  0.0208  0.3889 -0.25    0.0486  0.3333  2.7431 -1.5417  0.7778]\n",
      " [-0.5417 -0.2917  0.75   -0.4167  0.7083  0.75   -1.5417  3.5833 -0.1667]\n",
      " [-0.1389 -0.6667  0.5278  1.0833  1.1389  1.1667  0.7778 -0.1667  3.7222]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "[7.6854e+00 5.4920e+00 3.5973e+00 2.6693e+00 1.8620e-01 6.3000e-03\n",
      " 1.6726e+00 9.4870e-01 1.1867e+00]\n",
      "\n",
      "The Eigen vectors are :\n",
      "\n",
      "[[ 0.4002  0.2255 -0.1497 -0.5283 -0.5619  0.044   0.1475  0.3568  0.144 ]\n",
      " [ 0.2452 -0.0819  0.2337 -0.2483  0.3514  0.0224 -0.2274  0.4255 -0.6783]\n",
      " [-0.238  -0.0087  0.1633 -0.2989 -0.2643  0.065   0.4672 -0.506  -0.528 ]\n",
      " [-0.1117  0.3283 -0.7175  0.1527  0.2752 -0.0023  0.403   0.2088 -0.2448]\n",
      " [-0.4831  0.009   0.1505  0.1255 -0.1866  0.7323  0.0077  0.3963  0.0037]\n",
      " [-0.5005  0.0314  0.2267  0.0498 -0.2041 -0.6724  0.119   0.4316 -0.0219]\n",
      " [ 0.0467  0.5041  0.4811 -0.1799  0.475   0.0626  0.3867  0.0172  0.317 ]\n",
      " [-0.2794 -0.5628 -0.2201 -0.5893  0.3341  0.0162  0.1212  0.0649  0.2805]\n",
      " [-0.3828  0.5126 -0.166  -0.3855  0.038  -0.0286 -0.6061 -0.2103 -0.0263]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 4\n",
    "import numpy as np \n",
    "X=np.array([[16,16,13,18,16,15,14,16,16],\n",
    "            [18,19,15,16,18,18,18,17,19],\n",
    "            [17,17,14,14,17,17,20,14,15],\n",
    "            [17,17,17,16,18,18,16,20,14],\n",
    "            [16,15,17,17,18,18,19,16,19],\n",
    "            [15,17,16,17,18,18,15,19,16],\n",
    "            [17,16,16,18,18,18,17,15,18],\n",
    "            [20,18,16,20,15,15,19,14,17],\n",
    "            [14,16,18,17,19,19,18,17,18],\n",
    "            [16,16,15,19,18,18,18,15,14],\n",
    "            [18,19,16,14,14,14,17,16,13],\n",
    "            [19,15,15,18,16,16,18,19,17]])\n",
    "print('\\nGiven Matrix is \\n')\n",
    "print(X)\n",
    "print('\\nCol Means are \\n\\n{}'.format(np.round(X.mean(axis=0),4)))\n",
    "X=(X-np.mean(X,axis=0))\n",
    "print('\\nScaled Matrix is \\n')\n",
    "print(np.round(X,4))\n",
    "VarCov=np.dot(np.transpose(X),X)/len(X)\n",
    "print('\\nVariance Covariance Matrix is \\n')\n",
    "print(np.round(VarCov,4))\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}'.format(np.round(e1[0],4)))\n",
    "print('\\nThe Eigen vectors are :\\n')\n",
    "print(np.round(e1[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given Matrix is \n",
      "\n",
      "[[70 40 70]\n",
      " [70 70 10]\n",
      " [40 40 40]\n",
      " [40 40 70]\n",
      " [10 10 10]]\n",
      "\n",
      "Col Means are \n",
      "\n",
      "[46. 40. 40.]\n",
      "\n",
      "Scaled Matrix is \n",
      "\n",
      "[[ 24.   0.  30.]\n",
      " [ 24.  30. -30.]\n",
      " [ -6.   0.   0.]\n",
      " [ -6.   0.  30.]\n",
      " [-36. -30. -30.]]\n",
      "\n",
      "Variance Covariance Matrix is \n",
      "\n",
      "[[504. 360. 180.]\n",
      " [360. 360.   0.]\n",
      " [180.   0. 720.]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "44.81966028263878, 910.0699530410367, 629.1103866763253\n",
      "\n",
      "The Eigen vectors are :\n",
      "\n",
      "[[ 0.6487899  -0.65580225 -0.3859988 ]\n",
      " [-0.74104991 -0.4291978  -0.51636642]\n",
      " [-0.17296443 -0.62105769  0.7644414 ]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 5\n",
    "import numpy as np \n",
    "X=np.array([[70,40,70],[70,70,10],[40,40,40],[40,40,70],[10,10,10]])\n",
    "print('\\nGiven Matrix is \\n')\n",
    "print(X)\n",
    "print('\\nCol Means are \\n\\n{}'.format(X.mean(axis=0)))\n",
    "X = (X - np.mean(X, axis=0))\n",
    "print('\\nScaled Matrix is \\n')\n",
    "print(X)\n",
    "VarCov=np.dot(np.transpose(X),X)/len(X)\n",
    "print('\\nVariance Covariance Matrix is \\n')\n",
    "print(VarCov)\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}, {}, {}'.format(e1[0][0],e1[0][1],e1[0][2]))\n",
    "print('\\nThe Eigen vectors are :\\n')\n",
    "print(e1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[ 2.   4. ]\n",
      " [ 1.   3. ]\n",
      " [ 0.   1. ]\n",
      " [-1.   0.5]]\n",
      "\n",
      "Mean Values\n",
      "[0.5   2.125]\n",
      "\n",
      "Standardized Matrix is :\n",
      "[[ 1.5    1.875]\n",
      " [ 0.5    0.875]\n",
      " [-0.5   -1.125]\n",
      " [-1.5   -1.625]]\n",
      "\n",
      "Variance Covariance Matrix is\n",
      "[[1.25     1.5625  ]\n",
      " [1.5625   2.046875]]\n",
      "\n",
      "Eigen Values are \n",
      "[3.26093826 0.03593674]\n",
      "\n",
      "Eigen Vectors are \n",
      "[[-0.6135581  -0.78964958]\n",
      " [-0.78964958  0.6135581 ]]\n",
      "\n",
      "Threshold Table :\n",
      "[98.90997556853128, 100.0]\n",
      "\n",
      "Retained Eigen Values :\n",
      "[3.2609382570250163, 0.03593674297498417]\n",
      "\n",
      "Retained Eigen Vectors: \n",
      "[[-0.6135581  -0.78964958]\n",
      " [-0.78964958  0.6135581 ]]\n",
      "\n",
      " PCA Matrix :\n",
      "[[-4.38571451  0.87493326]\n",
      " [-2.98250683  1.05102473]\n",
      " [-0.78964958  0.6135581 ]\n",
      " [ 0.21873332  1.09642863]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 1\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[2,4],[1,3],[0,1],[-1,0.5]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean Values\\n{}'.format(np.mean(X,axis=0)))\n",
    "A=(X - np.mean(X, axis=0))\n",
    "print('\\nStandardized Matrix is :\\n{}'.format(A))\n",
    "VarCov=np.dot(np.transpose(A),A)/len(X)\n",
    "print('\\nVariance Covariance Matrix is\\n{}'.format(VarCov))\n",
    "eigenValues, eigenVectors = linalg.eig(VarCov)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]\n",
    "print('\\nEigen Values are \\n{}'.format(eigenValues))\n",
    "print('\\nEigen Vectors are \\n{}'.format(eigenVectors))\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "stoppoint=0\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z<=100:\n",
    "        stoppoint=i+1\n",
    "    t.append(z)\n",
    "print('\\nThreshold Table :\\n{}'.format(t))\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=eigenVectors[:,0:stoppoint]\n",
    "print('\\nRetained Eigen Values :\\n{}'.format(eigenValues))\n",
    "print('\\nRetained Eigen Vectors: \\n{}'.format(eigenVectors))\n",
    "print('\\n PCA Matrix :\\n{}'.format(np.dot(X,eigenVectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[90 60 90]\n",
      " [90 90 30]\n",
      " [60 60 60]\n",
      " [60 60 90]\n",
      " [30 30 30]]\n",
      "\n",
      "Mean Values\n",
      "[66. 60. 60.]\n",
      "\n",
      "Standardized Matrix is :\n",
      "[[ 24.   0.  30.]\n",
      " [ 24.  30. -30.]\n",
      " [ -6.   0.   0.]\n",
      " [ -6.   0.  30.]\n",
      " [-36. -30. -30.]]\n",
      "\n",
      "Variance Covariance Matrix is\n",
      "[[504. 360. 180.]\n",
      " [360. 360.   0.]\n",
      " [180.   0. 720.]]\n",
      "\n",
      "Eigen Values are \n",
      "[910.06995304 629.11038668  44.81966028]\n",
      "\n",
      "Eigen Vectors are \n",
      "[[-0.65580225 -0.3859988   0.6487899 ]\n",
      " [-0.4291978  -0.51636642 -0.74104991]\n",
      " [-0.62105769  0.7644414  -0.17296443]]\n",
      "\n",
      "Threshold Table :\n",
      "[57.453911176833095, 97.17047599225765, 100.0]\n",
      "\n",
      "Retained Eigen Values :\n",
      "[910.0699530410367, 629.1103866763253, 44.81966028263878]\n",
      "\n",
      "Retained Eigen Vectors: \n",
      "[[-0.65580225 -0.3859988   0.6487899 ]\n",
      " [-0.4291978  -0.51636642 -0.74104991]\n",
      " [-0.62105769  0.7644414  -0.17296443]]\n",
      "\n",
      " PCA Matrix :\n",
      "[[-140.6692628     3.07784927   -1.63870252]\n",
      " [-116.28173533  -58.27962721  -13.4923342 ]\n",
      " [-102.36346447   -8.27542884  -15.91346662]\n",
      " [-120.99519515   14.65781313  -21.10239948]\n",
      " [ -51.18173223   -4.13771442   -7.95673331]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 2\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[90,60,90],[90,90,30],[60,60,60],[60,60,90],[30,30,30]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean Values\\n{}'.format(np.mean(X,axis=0)))\n",
    "A=(X - np.mean(X, axis=0))\n",
    "print('\\nStandardized Matrix is :\\n{}'.format(A))\n",
    "VarCov=np.dot(np.transpose(A),A)/len(X)\n",
    "print('\\nVariance Covariance Matrix is\\n{}'.format(VarCov))\n",
    "eigenValues, eigenVectors = linalg.eig(VarCov)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]\n",
    "print('\\nEigen Values are \\n{}'.format(eigenValues))\n",
    "print('\\nEigen Vectors are \\n{}'.format(eigenVectors))\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "stoppoint=0\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z<=100:\n",
    "        stoppoint=i+1\n",
    "    t.append(z)\n",
    "print('\\nThreshold Table :\\n{}'.format(t))\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=eigenVectors[:,0:stoppoint]\n",
    "print('\\nRetained Eigen Values :\\n{}'.format(eigenValues))\n",
    "print('\\nRetained Eigen Vectors: \\n{}'.format(eigenVectors))\n",
    "print('\\n PCA Matrix :\\n{}'.format(np.dot(X,eigenVectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[7 4 3]\n",
      " [4 1 8]\n",
      " [6 3 5]\n",
      " [8 6 1]\n",
      " [8 5 7]\n",
      " [7 2 9]\n",
      " [5 3 3]\n",
      " [9 5 8]\n",
      " [7 4 5]\n",
      " [8 2 2]]\n",
      "\n",
      "Mean Values\n",
      "[6.9 3.5 5.1]\n",
      "\n",
      "Standardized Matrix is :\n",
      "[[ 0.1  0.5 -2.1]\n",
      " [-2.9 -2.5  2.9]\n",
      " [-0.9 -0.5 -0.1]\n",
      " [ 1.1  2.5 -4.1]\n",
      " [ 1.1  1.5  1.9]\n",
      " [ 0.1 -1.5  3.9]\n",
      " [-1.9 -0.5 -2.1]\n",
      " [ 2.1  1.5  2.9]\n",
      " [ 0.1  0.5 -0.1]\n",
      " [ 1.1 -1.5 -3.1]]\n",
      "\n",
      "Variance Covariance Matrix is\n",
      "[[ 2.09  1.45 -0.39]\n",
      " [ 1.45  2.25 -1.15]\n",
      " [-0.39 -1.15  7.09]]\n",
      "\n",
      "Eigen Values are \n",
      "[7.44654832 3.30851634 0.67493534]\n",
      "\n",
      "Eigen Vectors are \n",
      "[[-0.1375708   0.69903712 -0.70172743]\n",
      " [-0.25045969  0.66088917  0.70745703]\n",
      " [ 0.95830278  0.27307986  0.08416157]]\n",
      "\n",
      "Threshold Table :\n",
      "[65.14915417643986, 94.09505391500156, 100.0]\n",
      "\n",
      "Retained Eigen Values :\n",
      "[7.446548322367076, 3.3085163401176017, 0.6749353375153229]\n",
      "\n",
      "Retained Eigen Vectors: \n",
      "[[-0.1375708   0.69903712 -0.70172743]\n",
      " [-0.25045969  0.66088917  0.70745703]\n",
      " [ 0.95830278  0.27307986  0.08416157]]\n",
      "\n",
      " PCA Matrix :\n",
      "[[ 0.91007402  8.3560561  -1.82977916]\n",
      " [ 6.86567938  5.64167652 -1.42616015]\n",
      " [ 3.21471006  7.54228952 -1.66718563]\n",
      " [-1.64502171  9.83071184 -1.28491566]\n",
      " [ 4.35525466 10.80830182 -1.48740329]\n",
      " [ 7.16081008  8.67275691 -2.73972383]\n",
      " [ 1.4356753   6.29709269 -1.13378134]\n",
      " [ 5.17598665 11.7804188  -2.10496915]\n",
      " [ 2.82667958  8.90221581 -1.66145603]\n",
      " [ 0.31511981  7.46023502 -4.03058222]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 3\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[7,4,3],[4,1,8],[6,3,5],[8,6,1],[8,5,7],[7,2,9],[5,3,3],[9,5,8],[7,4,5],[8,2,2]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean Values\\n{}'.format(np.mean(X,axis=0)))\n",
    "A=(X - np.mean(X, axis=0))\n",
    "print('\\nStandardized Matrix is :\\n{}'.format(A))\n",
    "VarCov=np.dot(np.transpose(A),A)/len(X)\n",
    "print('\\nVariance Covariance Matrix is\\n{}'.format(VarCov))\n",
    "eigenValues, eigenVectors = linalg.eig(VarCov)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]\n",
    "print('\\nEigen Values are \\n{}'.format(eigenValues))\n",
    "print('\\nEigen Vectors are \\n{}'.format(eigenVectors))\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "stoppoint=0\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z<=100:\n",
    "        stoppoint=i+1\n",
    "    t.append(z)\n",
    "print('\\nThreshold Table :\\n{}'.format(t))\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=eigenVectors[:,0:stoppoint]\n",
    "print('\\nRetained Eigen Values :\\n{}'.format(eigenValues))\n",
    "print('\\nRetained Eigen Vectors: \\n{}'.format(eigenVectors))\n",
    "print('\\n PCA Matrix :\\n{}'.format(np.dot(X,eigenVectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[16 16 13 18 16 15 14 16 16]\n",
      " [18 19 15 16 18 18 18 17 19]\n",
      " [17 17 14 14 17 17 20 14 15]\n",
      " [17 17 17 16 18 18 16 20 14]\n",
      " [16 15 17 17 18 18 19 16 19]\n",
      " [15 17 16 17 18 18 15 19 16]\n",
      " [17 16 16 18 18 18 17 15 18]\n",
      " [20 18 16 20 15 15 19 14 17]\n",
      " [14 16 18 17 19 19 18 17 18]\n",
      " [16 16 15 19 18 18 18 15 14]\n",
      " [18 19 16 14 14 14 17 16 13]\n",
      " [19 15 15 18 16 16 18 19 17]]\n",
      "\n",
      "Mean Values\n",
      "[16.92 16.75 15.67 17.   17.08 17.   17.42 16.5  16.33]\n",
      "\n",
      "Standardized Matrix is :\n",
      "[[-0.92 -0.75 -2.67  1.   -1.08 -2.   -3.42 -0.5  -0.33]\n",
      " [ 1.08  2.25 -0.67 -1.    0.92  1.    0.58  0.5   2.67]\n",
      " [ 0.08  0.25 -1.67 -3.   -0.08  0.    2.58 -2.5  -1.33]\n",
      " [ 0.08  0.25  1.33 -1.    0.92  1.   -1.42  3.5  -2.33]\n",
      " [-0.92 -1.75  1.33  0.    0.92  1.    1.58 -0.5   2.67]\n",
      " [-1.92  0.25  0.33  0.    0.92  1.   -2.42  2.5  -0.33]\n",
      " [ 0.08 -0.75  0.33  1.    0.92  1.   -0.42 -1.5   1.67]\n",
      " [ 3.08  1.25  0.33  3.   -2.08 -2.    1.58 -2.5   0.67]\n",
      " [-2.92 -0.75  2.33  0.    1.92  2.    0.58  0.5   1.67]\n",
      " [-0.92 -0.75 -0.67  2.    0.92  1.    0.58 -1.5  -2.33]\n",
      " [ 1.08  2.25  0.33 -3.   -3.08 -3.   -0.42 -0.5  -3.33]\n",
      " [ 2.08 -1.75 -0.67  1.   -1.08 -1.    0.58  2.5   0.67]]\n",
      "\n",
      "Variance Covariance Matrix is\n",
      "[[ 2.58  0.81 -0.53  0.33 -1.58 -1.5   0.87 -0.54 -0.14]\n",
      " [ 0.81  1.69 -0.08 -0.92 -0.73 -0.67  0.02 -0.29 -0.67]\n",
      " [-0.53 -0.08  1.72  0.    0.69  0.92  0.39  0.75  0.53]\n",
      " [ 0.33 -0.92  0.    3.    0.17  0.08 -0.25 -0.42  1.08]\n",
      " [-1.58 -0.73  0.69  0.17  2.08  2.17  0.05  0.71  1.14]\n",
      " [-1.5  -0.67  0.92  0.08  2.17  2.33  0.33  0.75  1.17]\n",
      " [ 0.87  0.02  0.39 -0.25  0.05  0.33  2.74 -1.54  0.78]\n",
      " [-0.54 -0.29  0.75 -0.42  0.71  0.75 -1.54  3.58 -0.17]\n",
      " [-0.14 -0.67  0.53  1.08  1.14  1.17  0.78 -0.17  3.72]]\n",
      "\n",
      "Eigen Values are \n",
      "[7.69 5.49 3.59 2.67 1.67 1.19 0.95 0.18 0.  ]\n",
      "\n",
      "Eigen Vectors are \n",
      "[[ 0.4   0.23 -0.15 -0.53  0.15  0.15  0.36 -0.56  0.06]\n",
      " [ 0.25 -0.08  0.24 -0.25 -0.23 -0.68  0.43  0.35  0.01]\n",
      " [-0.24 -0.01  0.16 -0.3   0.47 -0.53 -0.5  -0.27  0.08]\n",
      " [-0.11  0.33 -0.72  0.15  0.4  -0.24  0.21  0.27 -0.01]\n",
      " [-0.48  0.01  0.15  0.13  0.01  0.01  0.4  -0.16  0.74]\n",
      " [-0.5   0.03  0.23  0.05  0.12 -0.02  0.43 -0.22 -0.67]\n",
      " [ 0.05  0.5   0.48 -0.18  0.39  0.32  0.01  0.48  0.05]\n",
      " [-0.28 -0.56 -0.22 -0.59  0.12  0.28  0.06  0.34  0.01]\n",
      " [-0.38  0.51 -0.16 -0.39 -0.61 -0.03 -0.21  0.04 -0.03]]\n",
      "\n",
      "Threshold Table :\n",
      "[ 32.82  56.25  71.57  82.97  90.1   95.18  99.23 100.   100.  ]\n",
      "\n",
      "Retained Eigen Values :\n",
      "[7.69 5.49 3.59 2.67 1.67 1.19 0.95 0.18 0.  ]\n",
      "\n",
      "Retained Eigen Vectors: \n",
      "[[ 0.4   0.23 -0.15 -0.53  0.15  0.15  0.36 -0.56  0.06]\n",
      " [ 0.25 -0.08  0.24 -0.25 -0.23 -0.68  0.43  0.35  0.01]\n",
      " [-0.24 -0.01  0.16 -0.3   0.47 -0.53 -0.5  -0.27  0.08]\n",
      " [-0.11  0.33 -0.72  0.15  0.4  -0.24  0.21  0.27 -0.01]\n",
      " [-0.48  0.01  0.15  0.13  0.01  0.01  0.4  -0.16  0.74]\n",
      " [-0.5   0.03  0.23  0.05  0.12 -0.02  0.43 -0.22 -0.67]\n",
      " [ 0.05  0.5   0.48 -0.18  0.39  0.32  0.01  0.48  0.05]\n",
      " [-0.28 -0.56 -0.22 -0.59  0.12  0.28  0.06  0.34  0.01]\n",
      " [-0.38  0.51 -0.16 -0.39 -0.61 -0.03 -0.21  0.04 -0.03]]\n",
      "\n",
      " PCA Matrix :\n",
      "[[-19.74  15.02  -2.95 -29.05  11.61 -11.35  20.51   4.93   4.15]\n",
      " [-22.13  17.64   1.44 -33.83  11.59 -12.24  22.66   5.18   4.07]\n",
      " [-19.13  17.52   4.27 -30.01  13.36 -10.09  21.37   4.93   4.05]\n",
      " [-22.55  12.32   0.61 -32.86  15.47 -11.74  21.65   4.36   4.23]\n",
      " [-24.19  18.87   1.08 -31.81  13.82 -11.08  19.38   4.77   4.1 ]\n",
      " [-23.75  13.28  -0.55 -31.36  13.37 -12.41  21.15   5.28   3.9 ]\n",
      " [-22.85  18.41  -0.29 -30.8   13.38 -12.21  21.01   3.76   4.  ]\n",
      " [-17.67  20.53  -1.5  -32.51  15.05 -13.18  21.05   5.04   4.09]\n",
      " [-25.91  16.79   1.62 -31.14  14.23 -12.61  19.68   5.41   4.13]\n",
      " [-21.55  16.98   0.1  -28.44  15.99 -11.63  22.21   5.18   4.02]\n",
      " [-15.72  13.81   2.22 -32.04  13.89 -12.67  19.61   4.83   4.01]\n",
      " [-20.79  16.63  -1.99 -33.82  14.66  -9.21  20.6    5.12   4.01]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 4\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=X=np.array([[16,16,13,18,16,15,14,16,16],\n",
    "            [18,19,15,16,18,18,18,17,19],\n",
    "            [17,17,14,14,17,17,20,14,15],\n",
    "            [17,17,17,16,18,18,16,20,14],\n",
    "            [16,15,17,17,18,18,19,16,19],\n",
    "            [15,17,16,17,18,18,15,19,16],\n",
    "            [17,16,16,18,18,18,17,15,18],\n",
    "            [20,18,16,20,15,15,19,14,17],\n",
    "            [14,16,18,17,19,19,18,17,18],\n",
    "            [16,16,15,19,18,18,18,15,14],\n",
    "            [18,19,16,14,14,14,17,16,13],\n",
    "            [19,15,15,18,16,16,18,19,17]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "m=np.round(np.mean(X,axis=0),2)\n",
    "print('\\nMean Values\\n{}'.format(m))\n",
    "A=(X-m)\n",
    "print('\\nStandardized Matrix is :\\n{}'.format(A))\n",
    "VarCov=np.round(np.dot(np.transpose(A),A)/len(X),2)\n",
    "print('\\nVariance Covariance Matrix is\\n{}'.format(VarCov))\n",
    "eigenValues, eigenVectors = linalg.eig(VarCov)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = np.round(eigenValues[idx],2)\n",
    "eigenVectors = np.round(eigenVectors[:,idx],2)\n",
    "print('\\nEigen Values are \\n{}'.format(eigenValues))\n",
    "print('\\nEigen Vectors are \\n{}'.format(eigenVectors))\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "stoppoint=0\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z<=100:\n",
    "        stoppoint=i+1\n",
    "    t.append(z)\n",
    "t=np.round(t,2)\n",
    "print('\\nThreshold Table :\\n{}'.format(t))\n",
    "eigenValues=np.round(eigenValues.tolist(),2)\n",
    "eigenValues=np.round(eigenValues[0:stoppoint],2)\n",
    "eigenVectors=np.round(eigenVectors[:,0:stoppoint],2)\n",
    "print('\\nRetained Eigen Values :\\n{}'.format(eigenValues))\n",
    "print('\\nRetained Eigen Vectors: \\n{}'.format(eigenVectors))\n",
    "print('\\n PCA Matrix :\\n{}'.format(np.dot(X,eigenVectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[70 40 70]\n",
      " [70 70 10]\n",
      " [40 40 40]\n",
      " [40 40 70]\n",
      " [10 10 10]]\n",
      "\n",
      "Mean Values\n",
      "[46. 40. 40.]\n",
      "\n",
      "Standardized Matrix is :\n",
      "[[ 24.   0.  30.]\n",
      " [ 24.  30. -30.]\n",
      " [ -6.   0.   0.]\n",
      " [ -6.   0.  30.]\n",
      " [-36. -30. -30.]]\n",
      "\n",
      "Variance Covariance Matrix is\n",
      "[[504. 360. 180.]\n",
      " [360. 360.   0.]\n",
      " [180.   0. 720.]]\n",
      "\n",
      "Eigen Values are \n",
      "[910.06995304 629.11038668  44.81966028]\n",
      "\n",
      "Eigen Vectors are \n",
      "[[-0.65580225 -0.3859988   0.6487899 ]\n",
      " [-0.4291978  -0.51636642 -0.74104991]\n",
      " [-0.62105769  0.7644414  -0.17296443]]\n",
      "\n",
      "Threshold Table :\n",
      "[57.453911176833095, 97.17047599225765, 100.0]\n",
      "\n",
      "Retained Eigen Values :\n",
      "[910.0699530410367, 629.1103866763253, 44.81966028263878]\n",
      "\n",
      "Retained Eigen Vectors: \n",
      "[[-0.65580225 -0.3859988   0.6487899 ]\n",
      " [-0.4291978  -0.51636642 -0.74104991]\n",
      " [-0.62105769  0.7644414  -0.17296443]]\n",
      "\n",
      " PCA Matrix :\n",
      "[[-106.54810798    5.83632555    3.66578635]\n",
      " [ -82.1605805   -55.52115093   -8.18784533]\n",
      " [ -68.24230964   -5.51695256  -10.60897774]\n",
      " [ -86.87404033   17.41628941  -15.7979106 ]\n",
      " [ -17.06057741   -1.37923814   -2.65224444]]\n"
     ]
    }
   ],
   "source": [
    "# PCA 5\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[70,40,70],[70,70,10],[40,40,40],[40,40,70],[10,10,10]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean Values\\n{}'.format(np.mean(X,axis=0)))\n",
    "A=(X - np.mean(X, axis=0))\n",
    "print('\\nStandardized Matrix is :\\n{}'.format(A))\n",
    "VarCov=np.dot(np.transpose(A),A)/len(X)\n",
    "print('\\nVariance Covariance Matrix is\\n{}'.format(VarCov))\n",
    "eigenValues, eigenVectors = linalg.eig(VarCov)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]\n",
    "print('\\nEigen Values are \\n{}'.format(eigenValues))\n",
    "print('\\nEigen Vectors are \\n{}'.format(eigenVectors))\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "stoppoint=0\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z<=100:\n",
    "        stoppoint=i+1\n",
    "    t.append(z)\n",
    "print('\\nThreshold Table :\\n{}'.format(t))\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=eigenVectors[:,0:stoppoint]\n",
    "print('\\nRetained Eigen Values :\\n{}'.format(eigenValues))\n",
    "print('\\nRetained Eigen Vectors: \\n{}'.format(eigenVectors))\n",
    "print('\\n PCA Matrix :\\n{}'.format(np.dot(X,eigenVectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  6  5]\n",
      " [ 7  3  3]\n",
      " [10  9  8]\n",
      " [ 3  9  7]\n",
      " [10  6  5]]\n",
      "[6.6 6.6 5.6]\n",
      "[3.5 2.5 1.9]\n",
      "\n",
      "Dependent Matrix is :\n",
      "\n",
      "[[-1.02647871 -0.23904572 -0.30779351]\n",
      " [ 0.11405319 -1.43427433 -1.33377186]\n",
      " [ 0.96945211  0.95618289  1.23117402]\n",
      " [-1.02647871  0.95618289  0.71818485]\n",
      " [ 0.96945211 -0.23904572 -0.30779351]]\n",
      "\n",
      "Variance Covariance Matrix is :\n",
      "\n",
      "[[ 0.8        -0.04089589  0.06435886]\n",
      " [-0.04089589  0.8         0.78481835]\n",
      " [ 0.06435886  0.78481835  0.8       ]]\n",
      "\n",
      "The Eigen values are :\n",
      "\n",
      "[0.00818443 0.80664506 1.5851705 ]\n",
      "\n",
      "The eigen vectors are :\n",
      "\n",
      "[[-0.09360247 -0.99538347  0.0212208 ]\n",
      " [-0.70330551  0.08119286  0.70623585]\n",
      " [ 0.70469847 -0.05118071  0.70765853]]\n"
     ]
    }
   ],
   "source": [
    "# FA 1\n",
    "import numpy as np\n",
    "import math\n",
    "X=np.array([[3,6,5],[7,3,3],[10,9,8],[3,9,7],[10,6,5]])\n",
    "print(X)\n",
    "print(np.mean(X,axis=0))\n",
    "print(np.round((np.std(X,axis=0)*math.sqrt(len(X)/(len(X)-1))),1))\n",
    "X=(X-np.mean(X,axis=0))/(np.std(X,axis=0)*math.sqrt(len(X)/(len(X)-1)))\n",
    "print('\\nDependent Matrix is :\\n\\n{}'.format(X))\n",
    "A=X\n",
    "VarCov=np.dot(np.transpose(A),A)/len(X)\n",
    "print('\\nVariance Covariance Matrix is :\\n\\n{}'.format(VarCov))\n",
    "e1=np.linalg.eig(VarCov)\n",
    "print('\\nThe Eigen values are :\\n\\n{}'.format(e1[0]))\n",
    "print('\\nThe eigen vectors are :\\n')\n",
    "print(e1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[ 3  6  5]\n",
      " [ 7  3  3]\n",
      " [10  9  8]\n",
      " [ 3  9  7]\n",
      " [10  6  5]]\n",
      "\n",
      "Mean matrix : \n",
      " [6.6 6.6 5.6]\n",
      "\n",
      "Standard deviation matrix :\n",
      " [3.51 2.51 1.95]\n",
      "\n",
      "Dependent Matrix is:\n",
      "[[-1.03 -0.24 -0.31]\n",
      " [ 0.11 -1.43 -1.33]\n",
      " [ 0.97  0.96  1.23]\n",
      " [-1.03  0.96  0.72]\n",
      " [ 0.97 -0.24 -0.31]]\n",
      "\n",
      "Variance covariance matrix :\n",
      "[[ 0.8  -0.04  0.06]\n",
      " [-0.04  0.8   0.78]\n",
      " [ 0.06  0.78  0.8 ]]\n",
      "\n",
      "Eigen vectors are :\n",
      " [[ 0.02 -1.   -0.09]\n",
      " [ 0.71  0.08 -0.7 ]\n",
      " [ 0.71 -0.05  0.7 ]]\n",
      "\n",
      "Percentage of variance explained :\n",
      " [ 65.83  99.58 100.  ]\n",
      "\n",
      "New eigen values :\n",
      " [1.58, 0.81]\n",
      "\n",
      "New eigen vectors :\n",
      " [[ 0.02 -1.  ]\n",
      " [ 0.71  0.08]\n",
      " [ 0.71 -0.05]]\n",
      "\n",
      "Factor Loadings :\n",
      "\n",
      "0.0251  -0.9\n",
      "0.8925  0.072\n",
      "0.8925  -0.045\n",
      "\n",
      "Enter the angle of rotation : 2\n",
      "\n",
      "Trans matrix :\n",
      " [[ 0.9994 -0.0349]\n",
      " [ 0.0349  0.9994]]\n",
      "\n",
      "New loadings :\n",
      " [[ 0.05649494 -0.89858401]\n",
      " [ 0.8894517   0.10310505]\n",
      " [ 0.893535   -0.01382475]]\n"
     ]
    }
   ],
   "source": [
    "# FA 1\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[3,6,5],[7,3,3],[10,9,8],[3,9,7],[10,6,5]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean matrix : \\n',np.mean(X,axis=0))\n",
    "std=np.round(np.std(X,axis=0)*math.sqrt(len(X)/(len(X)-1)),2)\n",
    "print('\\nStandard deviation matrix :\\n',std)\n",
    "X=np.round((X-np.mean(X,axis=0))/std,2)\n",
    "print('\\nDependent Matrix is:\\n{}'.format(X))\n",
    "A=X\n",
    "VarCov=np.round(np.dot(np.transpose(A),A)/len(X),2)\n",
    "print('\\nVariance covariance matrix :\\n{}'.format(VarCov))\n",
    "eigenValues,eigenVectors=linalg.eig(VarCov)\n",
    "idx=eigenValues.argsort()[::-1]   \n",
    "eigenValues=np.round(eigenValues[idx],2)\n",
    "eigenVectors=np.round(eigenVectors[:,idx],2)\n",
    "print('\\nEigen vectors are :\\n',eigenVectors)\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z>90:\n",
    "        stoppoint=i\n",
    "    t.append(z)\n",
    "t=np.round(t,2)\n",
    "print('\\nPercentage of variance explained :\\n',t)\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=np.delete(eigenVectors,stoppoint,1)\n",
    "print('\\nNew eigen values :\\n',eigenValues)\n",
    "print('\\nNew eigen vectors :\\n',eigenVectors)\n",
    "print('\\nFactor Loadings :\\n')\n",
    "f1=np.round(eigenVectors[:,0]*math.sqrt(abs(eigenValues[0])),4)\n",
    "f2=np.round(eigenVectors[:,1]*math.sqrt(abs(eigenValues[1])),4)\n",
    "for i in range(len(f1)):\n",
    "    print(\"{}  {}\".format(f1[i],f2[i]))\n",
    "Z=np.array([f1,f2])\n",
    "angle=int(input('\\nEnter the angle of rotation : '))\n",
    "angle=math.radians(angle)\n",
    "TransMat=np.round(np.array([[math.cos(angle),-math.sin(angle)],[math.sin(angle),math.cos(angle)]]),4)\n",
    "print('\\nTrans matrix :\\n',TransMat)\n",
    "print('\\nNew loadings :\\n',np.transpose(np.dot(TransMat,Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gven Matrix is :\n",
      "[[14  7  8  7  7 13  7]\n",
      " [10  7  6  4  3 14  7]\n",
      " [ 8  5  5 10  5 12  5]\n",
      " [ 2  4  7 16  7 11  3]\n",
      " [ 6  2  4 13  3 10  3]]\n",
      "\n",
      "Mean matrix : \n",
      " [ 8.  5.  6. 10.  5. 12.  5.]\n",
      "\n",
      "Standard deviation matrix :\n",
      " [4.47 2.12 1.58 4.74 2.   1.58 2.  ]\n",
      "\n",
      "Dependent Matrix is:\n",
      "[[ 1.34  0.94  1.27 -0.63  1.    0.63  1.  ]\n",
      " [ 0.45  0.94  0.   -1.27 -1.    1.27  1.  ]\n",
      " [ 0.    0.   -0.63  0.    0.    0.    0.  ]\n",
      " [-1.34 -0.47  0.63  1.27  1.   -0.63 -1.  ]\n",
      " [-0.45 -1.42 -1.27  0.63 -1.   -1.27 -1.  ]]\n",
      "\n",
      "Variance covariance matrix :\n",
      "[[ 0.8   0.59  0.29 -0.68  0.    0.57  0.72]\n",
      " [ 0.59  0.8   0.54 -0.66  0.19  0.78  0.75]\n",
      " [ 0.29  0.54  0.8  -0.16  0.63  0.4   0.38]\n",
      " [-0.68 -0.66 -0.16  0.8   0.26 -0.72 -0.76]\n",
      " [ 0.    0.19  0.63  0.26  0.8   0.    0.  ]\n",
      " [ 0.57  0.78  0.4  -0.72  0.    0.8   0.76]\n",
      " [ 0.72  0.75  0.38 -0.76  0.    0.76  0.8 ]]\n",
      "\n",
      "Eigen vectors are :\n",
      " [[ 0.4   0.11  0.8   0.04 -0.1   0.42 -0.06]\n",
      " [ 0.45 -0.11 -0.3  -0.24 -0.54 -0.02 -0.59]\n",
      " [ 0.27 -0.58 -0.09  0.76  0.02  0.    0.02]\n",
      " [-0.42 -0.31  0.01 -0.09  0.39  0.48 -0.58]\n",
      " [ 0.05 -0.72  0.21 -0.55 -0.02 -0.15  0.31]\n",
      " [ 0.44  0.06 -0.46 -0.18  0.28  0.59  0.35]\n",
      " [ 0.45  0.09  0.08 -0.09  0.69 -0.47 -0.28]]\n",
      "\n",
      "Percentage of variance explained :\n",
      " [ 68.21  94.11  99.11 100.18 100.18 100.18 100.  ]\n",
      "\n",
      "New eigen values :\n",
      " [3.82, 1.45, 0.28, 0.06, 0.0, -0.0]\n",
      "\n",
      "New eigen vectors :\n",
      " [[ 0.4   0.11  0.8   0.04 -0.1   0.42]\n",
      " [ 0.45 -0.11 -0.3  -0.24 -0.54 -0.02]\n",
      " [ 0.27 -0.58 -0.09  0.76  0.02  0.  ]\n",
      " [-0.42 -0.31  0.01 -0.09  0.39  0.48]\n",
      " [ 0.05 -0.72  0.21 -0.55 -0.02 -0.15]\n",
      " [ 0.44  0.06 -0.46 -0.18  0.28  0.59]\n",
      " [ 0.45  0.09  0.08 -0.09  0.69 -0.47]]\n",
      "\n",
      "Factor Loadings :\n",
      "\n",
      "0.7818  0.1325\n",
      "0.8795  -0.1325\n",
      "0.5277  -0.6984\n",
      "-0.8209  -0.3733\n",
      "0.0977  -0.867\n",
      "0.86  0.0722\n",
      "0.8795  0.1084\n",
      "\n",
      "Enter the angle of rotation : 5\n",
      "\n",
      "Trans matrix :\n",
      " [[ 0.9962 -0.0872]\n",
      " [ 0.0872  0.9962]]\n",
      "\n",
      "New loadings :\n",
      " [[ 0.76727516  0.20016946]\n",
      " [ 0.8877119  -0.0553041 ]\n",
      " [ 0.58659522 -0.64973064]\n",
      " [-0.78522882 -0.44346394]\n",
      " [ 0.17293114 -0.85518596]\n",
      " [ 0.85043616  0.14691764]\n",
      " [ 0.86670542  0.18468048]]\n"
     ]
    }
   ],
   "source": [
    "# FA 2\n",
    "import numpy as np \n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "X=np.array([[14,7,8,7,7,13,7],[10,7,6,4,3,14,7],[8,5,5,10,5,12,5],[2,4,7,16,7,11,3],[6,2,4,13,3,10,3]])\n",
    "print('\\nGven Matrix is :\\n{}'.format(X))\n",
    "print('\\nMean matrix : \\n',np.mean(X,axis=0))\n",
    "std=np.round(np.std(X,axis=0)*math.sqrt(len(X)/(len(X)-1)),2)\n",
    "print('\\nStandard deviation matrix :\\n',std)\n",
    "X=np.round((X-np.mean(X,axis=0))/std,2)\n",
    "print('\\nDependent Matrix is:\\n{}'.format(X))\n",
    "A=X\n",
    "VarCov=np.round(np.dot(np.transpose(A),A)/len(X),2)\n",
    "print('\\nVariance covariance matrix :\\n{}'.format(VarCov))\n",
    "eigenValues,eigenVectors=linalg.eig(VarCov)\n",
    "idx=eigenValues.argsort()[::-1]   \n",
    "eigenValues=np.round(eigenValues[idx],2)\n",
    "eigenVectors=np.round(eigenVectors[:,idx],2)\n",
    "print('\\nEigen vectors are :\\n',eigenVectors)\n",
    "s=sum(list(eigenValues))\n",
    "t=[]\n",
    "for i in range(np.size(eigenValues)):\n",
    "    l=list(eigenValues)\n",
    "    numerator=sum(l[0:i+1])\n",
    "    z=(numerator/s)*100\n",
    "    if z>90:\n",
    "        stoppoint=i\n",
    "    t.append(z)\n",
    "t=np.round(t,2)\n",
    "print('\\nPercentage of variance explained :\\n',t)\n",
    "eigenValues=eigenValues.tolist()\n",
    "eigenValues=eigenValues[0:stoppoint]\n",
    "eigenVectors=np.delete(eigenVectors,stoppoint,1)\n",
    "print('\\nNew eigen values :\\n',eigenValues)\n",
    "print('\\nNew eigen vectors :\\n',eigenVectors)\n",
    "print('\\nFactor Loadings :\\n')\n",
    "f1=np.round(eigenVectors[:,0]*math.sqrt(abs(eigenValues[0])),4)\n",
    "f2=np.round(eigenVectors[:,1]*math.sqrt(abs(eigenValues[1])),4)\n",
    "for i in range(len(f1)):\n",
    "    print(\"{}  {}\".format(f1[i],f2[i]))\n",
    "Z=np.array([f1,f2])\n",
    "angle=int(input('\\nEnter the angle of rotation : '))\n",
    "angle=math.radians(angle)\n",
    "TransMat=np.round(np.array([[math.cos(angle),-math.sin(angle)],[math.sin(angle),math.cos(angle)]]),4)\n",
    "print('\\nTrans matrix :\\n',TransMat)\n",
    "print('\\nNew loadings :\\n',np.transpose(np.dot(TransMat,Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         2.         1.41421356 2.        ]\n",
      " [3.         4.         3.31662479 2.        ]\n",
      " [1.         6.         3.74165739 3.        ]\n",
      " [5.         7.         4.24264069 5.        ]]\n",
      "\n",
      "\n",
      "Dendogram:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CA 1\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "from matplotlib import pyplot as plt\n",
    "X=np.array([[5,4,7],\n",
    "    [3,6,1],\n",
    "    [6,4,8],\n",
    "    [2,4,4],\n",
    "    [1,1,3]])\n",
    "linked=linkage(X,'single')\n",
    "print(linked)\n",
    "labelList=['A','B','C','D','E']\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='ascending',\n",
    "            show_leaf_counts=True)\n",
    "print('\\n\\nDendogram:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          2.          7.61577311  2.        ]\n",
      " [ 1.          5.          9.          3.        ]\n",
      " [ 3.          6.          9.69535971  4.        ]\n",
      " [ 4.          7.         11.87434209  5.        ]]\n",
      "\n",
      "\n",
      "Dendogram:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CA 2\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "X=np.array([[0,0,0,0,0],\n",
    "    [9,0,0,0,0],\n",
    "    [3,7,0,0,0],\n",
    "    [6,5,9,0,0],\n",
    "    [11,10,2,8,0]])\n",
    "linked=linkage(X,'single')\n",
    "print(linked)\n",
    "labelList=range(1,6)\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='ascending',\n",
    "            show_leaf_counts=True)\n",
    "print('\\n\\nDendogram:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         2.         1.41421356 2.        ]\n",
      " [3.         4.         3.31662479 2.        ]\n",
      " [1.         6.         3.74165739 3.        ]\n",
      " [5.         7.         4.24264069 5.        ]]\n",
      "\n",
      "\n",
      "Dendogram:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CA 3\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "X=np.array([[5,4,7],\n",
    "    [3,6,1],\n",
    "    [6,4,8],\n",
    "    [2,4,4],\n",
    "    [1,1,3]])\n",
    "linked=linkage(X,'single')\n",
    "print(linked)\n",
    "labelList=['A','B','C','D','E']\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='ascending',\n",
    "            show_leaf_counts=True)\n",
    "print('\\n\\nDendogram:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
